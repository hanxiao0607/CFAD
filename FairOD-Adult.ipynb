{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48045ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb4a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371947f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoEncoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d):\n",
    "        super(AE, self).__init__()\n",
    "        self.d = d\n",
    "        nodes = 2\n",
    "        if d > 100:\n",
    "            nodes = 8\n",
    "        self.ae = nn.Sequential(\n",
    "            nn.Linear(d, nodes),\n",
    "            nn.Linear(nodes, nodes),\n",
    "            nn.Linear(nodes, d)\n",
    "        ).to(cuda)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight).to(cuda)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.d)\n",
    "        x1 = self.ae(x)\n",
    "        return x1.view(-1, 1, self.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe000eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, dset, alpha, gamma, train_input, attribute, majority, minority, epochs, batch, \n",
    "          base_score, one_hot, IDCG, PV_assignment, fair = False):\n",
    "    \"\"\"\n",
    "    Model Training\n",
    "    Args:\n",
    "        model: model to be trained\n",
    "        dset: dataset\n",
    "        alpha: hyperparameter1\n",
    "        gamma: hyperparameter2\n",
    "        train_input: sample\n",
    "        attribute: sensitive attribute subgroups\n",
    "        majority: the majority subgroup\n",
    "        minority: the minority subgroup\n",
    "        epochs: training epoches\n",
    "        batch: minibatch size\n",
    "        base_score: the preobtained outlier score from the AE\n",
    "        one_hot: one-hot-encoding of sensitive attribute subgroups\n",
    "        IDCG: IDCG for each protected subgroup\n",
    "        PV_assignment: The dict indicating each subgroup's index information, i.e., 1th, 3th, 5th belonging to male, 2th, 4th, 6th belonging to female\n",
    "        fair: if False, will only train a standard AE, else will train FairOD.\n",
    "                Note that FairOD require the output of AE\n",
    "    Returns: statistical parity, group fidelity, and outlier score\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    running_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for e in range(train_input.shape[0] // batch):\n",
    "            cur_index = list(range(e * batch, (e + 1) * batch))\n",
    "            input_batch = train_input[cur_index]\n",
    "            x = torch.tensor(input_batch).float()\n",
    "            x = x.to(cuda)\n",
    "\n",
    "            x1 = model(x)\n",
    "            if x.shape != x1.shape:\n",
    "                x = np.reshape(x.data.cpu().numpy(), x1.shape)\n",
    "                x = Variable(torch.tensor(x)).to(cuda)\n",
    "            self_reconstruction_loss = nn.functional.mse_loss(x1, x, reduction='none').to(cuda)\n",
    "            self_reconstruction_loss = torch.sum(self_reconstruction_loss, dim=2).to(cuda)\n",
    "            self_reconstruction_loss = torch.reshape(self_reconstruction_loss, (self_reconstruction_loss.shape[0],))\n",
    "\n",
    "            if fair:\n",
    "                \"\"\"\n",
    "                in the paper: \n",
    "                one could one-hot-encode (OHE) the ð‘ƒð‘‰ into multiple variables and minimize the correlation of \n",
    "                outlier scores with each variable additively. That is, an outer sum would be added to \n",
    "                Eq. (12) that goes over the new OHE variables encoding the categorical ð‘ƒð‘‰ .\n",
    "                \"\"\"\n",
    "                os_mean = torch.mean(self_reconstruction_loss)\n",
    "                os_std = torch.std(self_reconstruction_loss)\n",
    "                one_hot = torch.tensor(one_hot).to(cuda)\n",
    "                Statistical_Parity = 0\n",
    "\n",
    "                for i in range(one_hot.shape[1]):\n",
    "                    cur_group = one_hot[:, i]\n",
    "                    pv_mean = torch.mean(cur_group)\n",
    "                    pv_std = torch.std(cur_group)\n",
    "                    Statistical_Parity += abs(\n",
    "                        (torch.sum(self_reconstruction_loss) - os_mean) * (torch.sum(cur_group) - pv_mean) / (os_std * pv_std))\n",
    "\n",
    "                Group_Fidelity = len(set(attribute))\n",
    "                for i in set(attribute):\n",
    "                    group_batch_index = list(set().intersection(PV_assignment[i], cur_index))\n",
    "                    for k in group_batch_index:\n",
    "                        j = k - e * batch\n",
    "                        Group_Fidelity -= (np.power(2, base_score[k]) - 1) / (IDCG[i] * torch.log2(1 +\n",
    "                                                                torch.sum(torch.sigmoid(self_reconstruction_loss[group_batch_index] - self_reconstruction_loss[j]))))\n",
    "\n",
    "                L = alpha * self_reconstruction_loss.mean() + (1 - alpha) * Statistical_Parity + gamma * Group_Fidelity\n",
    "            else:\n",
    "                L = self_reconstruction_loss.mean()\n",
    "            optimizer.zero_grad()\n",
    "            L.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += L.data.cpu().numpy()\n",
    "#             if e % 10 == 9:  # show loss every 30 mini-batches\n",
    "#                 print(f'[{epoch + 1},     {e + 1}] loss:{running_loss / 10:.2f}')\n",
    "#                 running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    total = torch.tensor(train_input).float()\n",
    "    total = total.to(cuda)\n",
    "    final_x1 = model(total)\n",
    "    if final_x1.shape != total.shape:\n",
    "        total = np.reshape(total.data.cpu().numpy(), final_x1.shape)\n",
    "        total = Variable(torch.tensor(total)).to(cuda)\n",
    "    final_score = nn.functional.mse_loss(final_x1, total, reduction='none').to(cuda)\n",
    "    final_score = torch.sum(final_score, dim=2).to(cuda)\n",
    "    final_score = torch.reshape(final_score, (final_score.shape[0],))\n",
    "    if not fair:\n",
    "        np.save(f'data/{dset}.npy', final_score.data.cpu().numpy())\n",
    "        return final_score.data.cpu().numpy()\n",
    "    else:\n",
    "        percentage = 95\n",
    "        final_score_numpy = final_score.data.cpu().numpy()\n",
    "        threshold = np.percentile(final_score_numpy, q=percentage)\n",
    "        a = 0\n",
    "        b = 0\n",
    "        for i in range(train_input.shape[0]):\n",
    "            if final_score_numpy[i] > threshold:\n",
    "                if attribute[i] == majority[0]:\n",
    "                    a += 1\n",
    "                elif attribute[i] == minority[0]:\n",
    "                    b += 1\n",
    "        r = (a / majority[1]) / (b / minority[1])\n",
    "        fairness = min(r, 1/r)\n",
    "\n",
    "        NDCG_a = 0\n",
    "        NDCG_b = 0\n",
    "        for j in PV_assignment[majority[0]]:\n",
    "            sum = 1 + torch.sum(final_score[PV_assignment[majority[0]]] >= final_score[j])\n",
    "            NDCG_a += (torch.pow(2, torch.tensor(base_score[j]).to(cuda)) - 1) / (IDCG[majority[0]] * torch.log2(sum.float()))\n",
    "\n",
    "        for j in PV_assignment[minority[0]]:\n",
    "            sum = 1 + torch.sum(final_score[PV_assignment[minority[0]]] >= final_score[j])\n",
    "            NDCG_b += (torch.pow(2, torch.tensor(base_score[j]).to(cuda)) - 1) / (IDCG[minority[0]] * torch.log2(sum.float()))\n",
    "        group_fidelity = 1 / (1 / NDCG_a.data.cpu().numpy() + 1/NDCG_b.data.cpu().numpy())\n",
    "        print('fairness:', fairness)\n",
    "        print('group_fidelity:', group_fidelity)\n",
    "        return fairness, group_fidelity, final_score.data.cpu().numpy()\n",
    "    \n",
    "def evalation(model, df_test, df_test_cf):\n",
    "    model.eval()\n",
    "    test_X = torch.tensor(df_test.iloc[:,1:-1].values.astype(np.float32)).float()\n",
    "    test_X = test_X.to(cuda)\n",
    "    test_X_hat = model(test_X)\n",
    "    if test_X_hat.shape != test_X.shape:\n",
    "        test_X = np.reshape(test_X.data.cpu().numpy(), test_X_hat.shape)\n",
    "        test_X = Variable(torch.tensor(test_X)).to(cuda)\n",
    "    final_score = nn.functional.mse_loss(test_X_hat, test_X, reduction='none').to(cuda)\n",
    "    final_score = torch.sum(final_score, dim=2).to(cuda)\n",
    "    final_score = torch.reshape(final_score, (final_score.shape[0],))\n",
    "    \n",
    "    test_X_cf = torch.tensor(df_test_cf.values.astype(np.float32)).float()\n",
    "    test_X_cf = test_X_cf.to(cuda)\n",
    "    test_X_cf_hat = model(test_X_cf)\n",
    "    if test_X_cf_hat.shape != test_X_cf.shape:\n",
    "        test_X_cf = np.reshape(test_X_cf.data.cpu().numpy(), test_X_cf_hat.shape)\n",
    "        test_X_cf = Variable(torch.tensor(test_X_cf)).to(cuda)\n",
    "    final_score_cf = nn.functional.mse_loss(test_X_cf_hat, test_X_cf, reduction='none').to(cuda)\n",
    "    final_score_cf = torch.sum(final_score_cf, dim=2).to(cuda)\n",
    "    final_score_cf = torch.reshape(final_score_cf, (final_score_cf.shape[0],))\n",
    "    return final_score.data.cpu().numpy(), final_score_cf.data.cpu().numpy()\n",
    "    \n",
    "def set_seed(seed = 0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def load_data(adult=0):\n",
    "    if not adult:\n",
    "        df_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "        df_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "        df_test_cf = pd.read_csv('data/test_cf.csv', index_col=0)\n",
    "    else:\n",
    "        df_train = pd.read_csv('data/adult_train.csv', index_col=0)\n",
    "        df_test = pd.read_csv('data/adult_test.csv', index_col=0)\n",
    "        df_test_cf = pd.read_csv('data/adult_do.csv', index_col=0)\n",
    "    return df_train, df_test, df_test_cf\n",
    "\n",
    "def get_thres(score, quantile=0.95):\n",
    "    return np.quantile(score, quantile)\n",
    "\n",
    "def get_fairness_res(test_Y, score, score_cf, thres):\n",
    "    print(\"F\")\n",
    "    pr = average_precision_score(y_true=test_Y, y_score=score)\n",
    "    roc = roc_auc_score(test_Y, score)\n",
    "    print('PR:', pr)\n",
    "    print('AUC-ROC:', roc)\n",
    "    pred = [1 if i > thres else 0 for i in score]\n",
    "    df_org = pd.DataFrame()\n",
    "    df_org['label'] = test_Y\n",
    "    df_org['pred'] = pred\n",
    "    print(classification_report(test_Y, pred, digits=5))\n",
    "    print(confusion_matrix(test_Y, pred))\n",
    "\n",
    "    \n",
    "    print('-'*60)\n",
    "    print('CF')\n",
    "    print('PR:', average_precision_score(y_true=test_Y, y_score=score_cf))\n",
    "    print('AUC-ROC:', roc_auc_score(test_Y, score_cf))\n",
    "    pred = [1 if i > thres else 0 for i in score_cf]\n",
    "    df_org['pred_cf'] = pred\n",
    "    print(classification_report(test_Y, pred, digits=5))\n",
    "    print(confusion_matrix(test_Y, pred))\n",
    "    total = len(df_org)\n",
    "    df_org['cf_changed'] = df_org['pred_cf'] - df_org['pred']\n",
    "    df_org_cf = df_org.groupby(['cf_changed']).count().reset_index(drop=False)\n",
    "    before_cf = sum(df_org_cf.loc[df_org_cf['cf_changed'] != 0]['label'].values)\n",
    "    cr = before_cf / total\n",
    "    print(f'The prediction changed: {cr}')\n",
    "    return df_org, pr, roc, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3242b26d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "PR: 0.2642230167279809\n",
      "AUC-ROC: 0.6564716319444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83684   0.99883   0.91069     12000\n",
      "           1    0.81818   0.02625   0.05087      2400\n",
      "\n",
      "    accuracy                        0.83674     14400\n",
      "   macro avg    0.82751   0.51254   0.48078     14400\n",
      "weighted avg    0.83373   0.83674   0.76738     14400\n",
      "\n",
      "[[11986    14]\n",
      " [ 2337    63]]\n",
      "------------------------------------------------------------\n",
      "CF\n",
      "PR: 0.25471795920629503\n",
      "AUC-ROC: 0.6408912326388889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83730   0.99492   0.90933     12000\n",
      "           1    0.56738   0.03333   0.06297      2400\n",
      "\n",
      "    accuracy                        0.83465     14400\n",
      "   macro avg    0.70234   0.51413   0.48615     14400\n",
      "weighted avg    0.79231   0.83465   0.76827     14400\n",
      "\n",
      "[[11939    61]\n",
      " [ 2320    80]]\n",
      "The prediction changed: 0.005555555555555556\n",
      "Using alpha: 0.9,   gamma:0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2896821/3874804019.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  one_hot = torch.tensor(one_hot).to(cuda)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairness: 0.8477422533297092\n",
      "group_fidelity: 0.4595331000986003\n",
      "F\n",
      "PR: 0.18846979288890897\n",
      "AUC-ROC: 0.5637683506944445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83332   0.99783   0.90819     12000\n",
      "           1    0.16129   0.00208   0.00411      2400\n",
      "\n",
      "    accuracy                        0.83188     14400\n",
      "   macro avg    0.49731   0.49996   0.45615     14400\n",
      "weighted avg    0.72132   0.83188   0.75751     14400\n",
      "\n",
      "[[11974    26]\n",
      " [ 2395     5]]\n",
      "------------------------------------------------------------\n",
      "CF\n",
      "PR: 0.18957472531099023\n",
      "AUC-ROC: 0.5442273958333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.83349   0.98817   0.90426     12000\n",
      "           1    0.17919   0.01292   0.02410      2400\n",
      "\n",
      "    accuracy                        0.82563     14400\n",
      "   macro avg    0.50634   0.50054   0.46418     14400\n",
      "weighted avg    0.72444   0.82563   0.75757     14400\n",
      "\n",
      "[[11858   142]\n",
      " [ 2369    31]]\n",
      "The prediction changed: 0.01138888888888889\n",
      "Final PR: 0.18846979288890897\n",
      "Final ROC: 0.5637683506944445\n",
      "FInal CR: 0.01138888888888889\n"
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "quantile = 0.999\n",
    "db = 'adult'\n",
    "df_train, df_test, df_test_cf = load_data(1)\n",
    "X_norm = df_train.iloc[:,1:-1].values.astype(np.float32)\n",
    "Y = df_train['y'].values\n",
    "sensitive_attribute_group = df_train.iloc[:,0].values\n",
    "input = np.reshape(sensitive_attribute_group, (-1, 1))\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(input)\n",
    "one_hot = enc.transform(input).toarray()\n",
    "sensitive_attribute_group = np.argmax(one_hot, axis=1)\n",
    "\n",
    "# -----data shuffling----- #\n",
    "set_seed(0)\n",
    "random_index = np.random.permutation(X_norm.shape[0])\n",
    "X_norm = X_norm[random_index]\n",
    "Y = Y[random_index]\n",
    "sensitive_attribute_group = sensitive_attribute_group[random_index]\n",
    "\n",
    "# -----setting epoch and minibatch size----- #\n",
    "starttime = time.time()\n",
    "configuration = 90, 64\n",
    "\n",
    "fair_command = 'f'\n",
    "\n",
    "test_Y = df_test['y']\n",
    "\n",
    "# -----train AE----- #\n",
    "if fair_command == 'f':\n",
    "    ae = AE(X_norm.shape[1]).to(cuda)\n",
    "    score = Train(ae, db, 0, 0, X_norm, [], [], [], configuration[0], configuration[1], NotImplemented, NotImplemented, NotImplemented, NotImplemented, fair=False)\n",
    "    thres = get_thres(score, quantile)\n",
    "    score, score_cf = evalation(ae, df_test, df_test_cf)\n",
    "    df_org,_,_,_ = get_fairness_res(test_Y, score, score_cf, thres)\n",
    "          \n",
    "\n",
    "else:\n",
    "    fair = True\n",
    "\n",
    "    \n",
    "    \n",
    "# -----cache IDCG and PV_assignment to facilitate model training----- #\n",
    "fair = True\n",
    "base_score = np.load(f'data/{db}.npy')\n",
    "base_score = (base_score - min(base_score)) / (max(base_score) - min(base_score))\n",
    "IDCG = defaultdict(float)\n",
    "PV_assignment = defaultdict(list)\n",
    "for i in range(X_norm.shape[0]):\n",
    "    PV_assignment[sensitive_attribute_group[i]].append(i)\n",
    "\n",
    "for i in set(sensitive_attribute_group):\n",
    "    scores = torch.tensor(base_score[PV_assignment[i]]).to(cuda)\n",
    "    scores, _ = torch.sort(scores, descending=True)\n",
    "    scores = scores.data.cpu().numpy()\n",
    "    for j in range(len(scores)):\n",
    "        IDCG[i] += (np.power(2, scores[j]) - 1) / np.log2(1 + (j + 1))\n",
    "\n",
    "c = Counter(sensitive_attribute_group)\n",
    "majority = c.most_common()[0]\n",
    "minority = c.most_common()[-1]\n",
    "\n",
    "# alpha = [0.01, 0.9]\n",
    "alpha = [0.9]\n",
    "# gamma = [0.01, 1.0]\n",
    "gamma = [0.01]\n",
    "best_choice = NotImplemented\n",
    "lst_pr = []\n",
    "lst_roc = []\n",
    "lst_cr = []\n",
    "\n",
    "for i in alpha:\n",
    "    for j in gamma:\n",
    "        print(f'Using alpha: {i},   gamma:{j}')\n",
    "        ae = AE(X_norm.shape[1]).to(cuda)\n",
    "        if db == 'kdd':\n",
    "            ae = nn.DataParallel(ae, device_ids=devices).to(cuda)\n",
    "        fairness, group_fidelity, final_scores = \\\n",
    "            Train(ae, db, i, j, X_norm, sensitive_attribute_group, majority, minority, configuration[0], configuration[1], base_score, one_hot, IDCG, PV_assignment, fair=fair)\n",
    "        # -----find the best combination of alpha and gamma in the hyperparameter grid ----- #\n",
    "        if best_choice is NotImplemented:\n",
    "            best_choice = (fairness, group_fidelity, final_scores, ae)\n",
    "        else:\n",
    "            current_best = best_choice[0] + best_choice[1]\n",
    "            if current_best < fairness + group_fidelity:\n",
    "                best_choice = (fairness, group_fidelity, final_scores, ae)\n",
    "        thres = get_thres(best_choice[2], quantile)\n",
    "        score, score_cf = evalation(best_choice[3], df_test, df_test_cf)\n",
    "        df_fair, pr, roc, cr = get_fairness_res(test_Y, score, score_cf, thres)\n",
    "        lst_pr.append(pr)\n",
    "        lst_roc.append(roc)\n",
    "        lst_cr.append(cr)\n",
    "print('Final PR:', np.array(lst_pr).mean())\n",
    "print('Final ROC:', np.array(lst_roc).mean())\n",
    "print('FInal CR:', np.array(lst_cr).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c35d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa7200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
