{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b2a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650697fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23167a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoEncoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d):\n",
    "        super(AE, self).__init__()\n",
    "        self.d = d\n",
    "        nodes = 64\n",
    "        if d > 100:\n",
    "            nodes = 8\n",
    "        self.ae = nn.Sequential(\n",
    "            nn.Linear(d, nodes),\n",
    "            nn.Linear(nodes, nodes),\n",
    "            nn.Linear(nodes, d)\n",
    "        ).to(cuda)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight).to(cuda)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.d)\n",
    "        x1 = self.ae(x)\n",
    "        return x1.view(-1, 1, self.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f932e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, dset, alpha, gamma, train_input, attribute, majority, minority, epochs, batch, \n",
    "          base_score, one_hot, IDCG, PV_assignment, fair = False):\n",
    "    \"\"\"\n",
    "    Model Training\n",
    "    Args:\n",
    "        model: model to be trained\n",
    "        dset: dataset\n",
    "        alpha: hyperparameter1\n",
    "        gamma: hyperparameter2\n",
    "        train_input: sample\n",
    "        attribute: sensitive attribute subgroups\n",
    "        majority: the majority subgroup\n",
    "        minority: the minority subgroup\n",
    "        epochs: training epoches\n",
    "        batch: minibatch size\n",
    "        base_score: the preobtained outlier score from the AE\n",
    "        one_hot: one-hot-encoding of sensitive attribute subgroups\n",
    "        IDCG: IDCG for each protected subgroup\n",
    "        PV_assignment: The dict indicating each subgroup's index information, i.e., 1th, 3th, 5th belonging to male, 2th, 4th, 6th belonging to female\n",
    "        fair: if False, will only train a standard AE, else will train FairOD.\n",
    "                Note that FairOD require the output of AE\n",
    "    Returns: statistical parity, group fidelity, and outlier score\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "    running_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for e in range(train_input.shape[0] // batch):\n",
    "            cur_index = list(range(e * batch, (e + 1) * batch))\n",
    "            input_batch = train_input[cur_index]\n",
    "            x = torch.tensor(input_batch).float()\n",
    "            x = x.to(cuda)\n",
    "\n",
    "            x1 = model(x)\n",
    "            if x.shape != x1.shape:\n",
    "                x = np.reshape(x.data.cpu().numpy(), x1.shape)\n",
    "                x = Variable(torch.tensor(x)).to(cuda)\n",
    "            self_reconstruction_loss = nn.functional.mse_loss(x1, x, reduction='none').to(cuda)\n",
    "            self_reconstruction_loss = torch.sum(self_reconstruction_loss, dim=2).to(cuda)\n",
    "            self_reconstruction_loss = torch.reshape(self_reconstruction_loss, (self_reconstruction_loss.shape[0],))\n",
    "\n",
    "            if fair:\n",
    "                \"\"\"\n",
    "                in the paper: \n",
    "                one could one-hot-encode (OHE) the ð‘ƒð‘‰ into multiple variables and minimize the correlation of \n",
    "                outlier scores with each variable additively. That is, an outer sum would be added to \n",
    "                Eq. (12) that goes over the new OHE variables encoding the categorical ð‘ƒð‘‰ .\n",
    "                \"\"\"\n",
    "                os_mean = torch.mean(self_reconstruction_loss)\n",
    "                os_std = torch.std(self_reconstruction_loss)\n",
    "                one_hot = torch.tensor(one_hot).to(cuda)\n",
    "                Statistical_Parity = 0\n",
    "\n",
    "                for i in range(one_hot.shape[1]):\n",
    "                    cur_group = one_hot[:, i]\n",
    "                    pv_mean = torch.mean(cur_group)\n",
    "                    pv_std = torch.std(cur_group)\n",
    "                    Statistical_Parity += abs(\n",
    "                        (torch.sum(self_reconstruction_loss) - os_mean) * (torch.sum(cur_group) - pv_mean) / (os_std * pv_std))\n",
    "\n",
    "                Group_Fidelity = len(set(attribute))\n",
    "                for i in set(attribute):\n",
    "                    group_batch_index = list(set().intersection(PV_assignment[i], cur_index))\n",
    "                    for k in group_batch_index:\n",
    "                        j = k - e * batch\n",
    "                        Group_Fidelity -= (np.power(2, base_score[k]) - 1) / (IDCG[i] * torch.log2(1 +\n",
    "                                                                torch.sum(torch.sigmoid(self_reconstruction_loss[group_batch_index] - self_reconstruction_loss[j]))))\n",
    "\n",
    "                L = alpha * self_reconstruction_loss.mean() + (1 - alpha) * Statistical_Parity + gamma * Group_Fidelity\n",
    "            else:\n",
    "                L = self_reconstruction_loss.mean()\n",
    "            optimizer.zero_grad()\n",
    "            L.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += L.data.cpu().numpy()\n",
    "#             if e % 10 == 9:  # show loss every 30 mini-batches\n",
    "#                 print(f'[{epoch + 1},     {e + 1}] loss:{running_loss / 10:.2f}')\n",
    "#                 running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    total = torch.tensor(train_input).float()\n",
    "    total = total.to(cuda)\n",
    "    final_x1 = model(total)\n",
    "    if final_x1.shape != total.shape:\n",
    "        total = np.reshape(total.data.cpu().numpy(), final_x1.shape)\n",
    "        total = Variable(torch.tensor(total)).to(cuda)\n",
    "    final_score = nn.functional.mse_loss(final_x1, total, reduction='none').to(cuda)\n",
    "    final_score = torch.sum(final_score, dim=2).to(cuda)\n",
    "    final_score = torch.reshape(final_score, (final_score.shape[0],))\n",
    "    if not fair:\n",
    "        np.save(f'data/{dset}.npy', final_score.data.cpu().numpy())\n",
    "        return final_score.data.cpu().numpy()\n",
    "    else:\n",
    "        percentage = 95\n",
    "        final_score_numpy = final_score.data.cpu().numpy()\n",
    "        threshold = np.percentile(final_score_numpy, q=percentage)\n",
    "        a = 0\n",
    "        b = 0\n",
    "        for i in range(train_input.shape[0]):\n",
    "            if final_score_numpy[i] > threshold:\n",
    "                if attribute[i] == majority[0]:\n",
    "                    a += 1\n",
    "                elif attribute[i] == minority[0]:\n",
    "                    b += 1\n",
    "        r = (a / majority[1]) / (b / minority[1])\n",
    "        fairness = min(r, 1/r)\n",
    "\n",
    "        NDCG_a = 0\n",
    "        NDCG_b = 0\n",
    "        for j in PV_assignment[majority[0]]:\n",
    "            sum = 1 + torch.sum(final_score[PV_assignment[majority[0]]] >= final_score[j])\n",
    "            NDCG_a += (torch.pow(2, torch.tensor(base_score[j]).to(cuda)) - 1) / (IDCG[majority[0]] * torch.log2(sum.float()))\n",
    "\n",
    "        for j in PV_assignment[minority[0]]:\n",
    "            sum = 1 + torch.sum(final_score[PV_assignment[minority[0]]] >= final_score[j])\n",
    "            NDCG_b += (torch.pow(2, torch.tensor(base_score[j]).to(cuda)) - 1) / (IDCG[minority[0]] * torch.log2(sum.float()))\n",
    "        group_fidelity = 1 / (1 / NDCG_a.data.cpu().numpy() + 1/NDCG_b.data.cpu().numpy())\n",
    "        print('fairness:', fairness)\n",
    "        print('group_fidelity:', group_fidelity)\n",
    "        return fairness, group_fidelity, final_score.data.cpu().numpy()\n",
    "    \n",
    "def evalation(model, df_test, df_test_cf):\n",
    "    model.eval()\n",
    "    test_X = torch.tensor(df_test.iloc[:,1:-3].values.astype(np.float32)).float()\n",
    "    test_X = test_X.to(cuda)\n",
    "    test_X_hat = model(test_X)\n",
    "    if test_X_hat.shape != test_X.shape:\n",
    "        test_X = np.reshape(test_X.data.cpu().numpy(), test_X_hat.shape)\n",
    "        test_X = Variable(torch.tensor(test_X)).to(cuda)\n",
    "    final_score = nn.functional.mse_loss(test_X_hat, test_X, reduction='none').to(cuda)\n",
    "    final_score = torch.sum(final_score, dim=2).to(cuda)\n",
    "    final_score = torch.reshape(final_score, (final_score.shape[0],))\n",
    "    \n",
    "    test_X_cf = torch.tensor(df_test_cf.iloc[:,1:-3].values.astype(np.float32)).float()\n",
    "    test_X_cf = test_X_cf.to(cuda)\n",
    "    test_X_cf_hat = model(test_X_cf)\n",
    "    if test_X_cf_hat.shape != test_X_cf.shape:\n",
    "        test_X_cf = np.reshape(test_X_cf.data.cpu().numpy(), test_X_cf_hat.shape)\n",
    "        test_X_cf = Variable(torch.tensor(test_X_cf)).to(cuda)\n",
    "    final_score_cf = nn.functional.mse_loss(test_X_cf_hat, test_X_cf, reduction='none').to(cuda)\n",
    "    final_score_cf = torch.sum(final_score_cf, dim=2).to(cuda)\n",
    "    final_score_cf = torch.reshape(final_score_cf, (final_score_cf.shape[0],))\n",
    "    return final_score.data.cpu().numpy(), final_score_cf.data.cpu().numpy()\n",
    "    \n",
    "def set_seed(seed = 0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def load_data(adult=0):\n",
    "    if not adult:\n",
    "        df_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "        df_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "        df_test_cf = pd.read_csv('data/test_cf.csv', index_col=0)\n",
    "    else:\n",
    "        df_train = pd.read_csv('data/adult_train.csv', index_col=0)\n",
    "        df_test = pd.read_csv('data/adult_test.csv', index_col=0)\n",
    "        df_test_cf = pd.read_csv('data/adult_do.csv', index_col=0)\n",
    "    return df_train, df_test, df_test_cf\n",
    "\n",
    "def get_thres(score, quantile=0.95):\n",
    "    return np.quantile(score, quantile)\n",
    "\n",
    "def get_fairness_res(test_Y, score, score_cf, thres):\n",
    "    print(\"F\")\n",
    "    pr = average_precision_score(y_true=test_Y, y_score=score)\n",
    "    roc = roc_auc_score(test_Y, score)\n",
    "    print('PR:', pr)\n",
    "    print('AUC-ROC:', roc)\n",
    "    pred = [1 if i > thres else 0 for i in score]\n",
    "    df_org = pd.DataFrame()\n",
    "    df_org['label'] = test_Y\n",
    "    df_org['pred'] = pred\n",
    "    print(classification_report(test_Y, pred, digits=5))\n",
    "    print(confusion_matrix(test_Y, pred))\n",
    "\n",
    "    \n",
    "    print('-'*60)\n",
    "    print('CF')\n",
    "    print('PR:', average_precision_score(y_true=test_Y, y_score=score_cf))\n",
    "    print('AUC-ROC:', roc_auc_score(test_Y, score_cf))\n",
    "    pred = [1 if i > thres else 0 for i in score_cf]\n",
    "    df_org['pred_cf'] = pred\n",
    "    print(classification_report(test_Y, pred, digits=5))\n",
    "    print(confusion_matrix(test_Y, pred))\n",
    "    total = len(df_org)\n",
    "    df_org['cf_changed'] = df_org['pred_cf'] - df_org['pred']\n",
    "    df_org_cf = df_org.groupby(['cf_changed']).count().reset_index(drop=False)\n",
    "    before_cf = sum(df_org_cf.loc[df_org_cf['cf_changed'] != 0]['label'].values)\n",
    "    cr = before_cf / total\n",
    "    print(f'The prediction changed: {cr}')\n",
    "    return df_org, pr, roc, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65db474e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "PR: 1.0\n",
      "AUC-ROC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.99875   0.99937      4000\n",
      "           1    0.98765   1.00000   0.99379       400\n",
      "\n",
      "    accuracy                        0.99886      4400\n",
      "   macro avg    0.99383   0.99938   0.99658      4400\n",
      "weighted avg    0.99888   0.99886   0.99887      4400\n",
      "\n",
      "[[3995    5]\n",
      " [   0  400]]\n",
      "------------------------------------------------------------\n",
      "CF\n",
      "PR: 0.409510337250768\n",
      "AUC-ROC: 0.72240875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98617   0.49900   0.66268      4000\n",
      "           1    0.15657   0.93000   0.26801       400\n",
      "\n",
      "    accuracy                        0.53818      4400\n",
      "   macro avg    0.57137   0.71450   0.46535      4400\n",
      "weighted avg    0.91075   0.53818   0.62680      4400\n",
      "\n",
      "[[1996 2004]\n",
      " [  28  372]]\n",
      "The prediction changed: 0.4611363636363636\n",
      "Using alpha: 0.99985,   gamma:0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2896725/3767815449.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  one_hot = torch.tensor(one_hot).to(cuda)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairness: 0.5044589500781466\n",
      "group_fidelity: 0.3770347328840995\n",
      "F\n",
      "PR: 0.6749309686755871\n",
      "AUC-ROC: 0.9501206249999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92210   0.99725   0.95820      4000\n",
      "           1    0.85135   0.15750   0.26582       400\n",
      "\n",
      "    accuracy                        0.92091      4400\n",
      "   macro avg    0.88673   0.57737   0.61201      4400\n",
      "weighted avg    0.91567   0.92091   0.89526      4400\n",
      "\n",
      "[[3989   11]\n",
      " [ 337   63]]\n",
      "------------------------------------------------------------\n",
      "CF\n",
      "PR: 0.14282956656652324\n",
      "AUC-ROC: 0.6424806249999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.91198   0.96875   0.93951      4000\n",
      "           1    0.17219   0.06500   0.09437       400\n",
      "\n",
      "    accuracy                        0.88659      4400\n",
      "   macro avg    0.54208   0.51687   0.51694      4400\n",
      "weighted avg    0.84473   0.88659   0.86268      4400\n",
      "\n",
      "[[3875  125]\n",
      " [ 374   26]]\n",
      "The prediction changed: 0.049772727272727274\n",
      "Final PR: 0.6749309686755871\n",
      "Final ROC: 0.9501206249999999\n",
      "FInal CR: 0.049772727272727274\n"
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "quantile = 0.999\n",
    "db = 'synthetic'\n",
    "df_train, df_test, df_test_cf = load_data(0)\n",
    "X_norm = df_train.iloc[:,1:-3].values.astype(np.float32)\n",
    "Y = df_train['label'].values\n",
    "sensitive_attribute_group = df_train.iloc[:,0].values\n",
    "input = np.reshape(sensitive_attribute_group, (-1, 1))\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(input)\n",
    "one_hot = enc.transform(input).toarray()\n",
    "sensitive_attribute_group = np.argmax(one_hot, axis=1)\n",
    "\n",
    "# -----data shuffling----- #\n",
    "set_seed(0)\n",
    "random_index = np.random.permutation(X_norm.shape[0])\n",
    "X_norm = X_norm[random_index]\n",
    "Y = Y[random_index]\n",
    "sensitive_attribute_group = sensitive_attribute_group[random_index]\n",
    "\n",
    "# -----setting epoch and minibatch size----- #\n",
    "starttime = time.time()\n",
    "configuration = 90, 64\n",
    "\n",
    "\n",
    "fair_command = 'f'\n",
    "\n",
    "test_Y = df_test['label']\n",
    "\n",
    "# -----train AE----- #\n",
    "if fair_command == 'f':\n",
    "    ae = AE(X_norm.shape[1]).to(cuda)\n",
    "    score = Train(ae, db, 0, 0, X_norm, [], [], [], configuration[0], configuration[1], NotImplemented, NotImplemented, NotImplemented, NotImplemented, fair=False)\n",
    "    thres = get_thres(score, quantile)\n",
    "    score, score_cf = evalation(ae, df_test, df_test_cf)\n",
    "    df_org, _, _, _ = get_fairness_res(test_Y, score, score_cf, thres)\n",
    "          \n",
    "\n",
    "else:\n",
    "    fair = True\n",
    "\n",
    "    \n",
    "    \n",
    "# -----cache IDCG and PV_assignment to facilitate model training----- #\n",
    "fair = True\n",
    "base_score = np.load(f'data/{db}.npy')\n",
    "base_score = (base_score - min(base_score)) / (max(base_score) - min(base_score))\n",
    "IDCG = defaultdict(float)\n",
    "PV_assignment = defaultdict(list)\n",
    "for i in range(X_norm.shape[0]):\n",
    "    PV_assignment[sensitive_attribute_group[i]].append(i)\n",
    "\n",
    "for i in set(sensitive_attribute_group):\n",
    "    scores = torch.tensor(base_score[PV_assignment[i]]).to(cuda)\n",
    "    scores, _ = torch.sort(scores, descending=True)\n",
    "    scores = scores.data.cpu().numpy()\n",
    "    for j in range(len(scores)):\n",
    "        IDCG[i] += (np.power(2, scores[j]) - 1) / np.log2(1 + (j + 1))\n",
    "\n",
    "c = Counter(sensitive_attribute_group)\n",
    "majority = c.most_common()[0]\n",
    "minority = c.most_common()[-1]\n",
    "\n",
    "# alpha = [0.01, 0.9]\n",
    "alpha = [0.99985]\n",
    "# gamma = [0.01, 1.0]\n",
    "gamma = [0.01]\n",
    "best_choice = NotImplemented\n",
    "lst_pr = []\n",
    "lst_roc = []\n",
    "lst_cr = []\n",
    "\n",
    "\n",
    "for i in alpha:\n",
    "    for j in gamma:\n",
    "        print(f'Using alpha: {i},   gamma:{j}')\n",
    "        ae = AE(X_norm.shape[1]).to(cuda)\n",
    "        if db == 'kdd':\n",
    "            ae = nn.DataParallel(ae, device_ids=devices).to(cuda)\n",
    "        fairness, group_fidelity, final_scores = \\\n",
    "            Train(ae, db, i, j, X_norm, sensitive_attribute_group, majority, minority, configuration[0], configuration[1], base_score, one_hot, IDCG, PV_assignment, fair=fair)\n",
    "        # -----find the best combination of alpha and gamma in the hyperparameter grid ----- #\n",
    "        if best_choice is NotImplemented:\n",
    "            best_choice = (fairness, group_fidelity, final_scores, ae)\n",
    "        else:\n",
    "            current_best = best_choice[0] + best_choice[1]\n",
    "            if current_best < fairness + group_fidelity:\n",
    "                best_choice = (fairness, group_fidelity, final_scores, ae)\n",
    "        thres = get_thres(best_choice[2], quantile)\n",
    "        score, score_cf = evalation(best_choice[3], df_test, df_test_cf)\n",
    "        df_fair, pr, roc, cr = get_fairness_res(test_Y, score, score_cf, thres)\n",
    "        lst_pr.append(pr)\n",
    "        lst_roc.append(roc)\n",
    "        lst_cr.append(cr)\n",
    "print('Final PR:', np.array(lst_pr).mean())\n",
    "print('Final ROC:', np.array(lst_roc).mean())\n",
    "print('FInal CR:', np.array(lst_cr).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89d582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24953570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eaa2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
